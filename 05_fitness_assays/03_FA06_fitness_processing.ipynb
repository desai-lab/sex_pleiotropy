{"cells":[{"cell_type":"code","execution_count":null,"id":"3a8458d8","metadata":{"id":"3a8458d8"},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import statsmodels.formula.api as smf"]},{"cell_type":"markdown","id":"88680bfa","metadata":{"id":"88680bfa"},"source":["# Build `GGE_FA6_Cleaned_with_s.txt` from `FA06_All.xls`\n","\n","**Input**: `FA06_All.xls` (FlowJo exports + `Plate_Layout_FA6`)\n","\n","**Output**: `GGE_FA6_Cleaned_with_s.txt`"]},{"cell_type":"code","execution_count":null,"id":"838c60f7","metadata":{"id":"838c60f7"},"outputs":[],"source":["FA06_XLS = Path('FA06_All.xls')\n","OUT_TXT  = Path('GGE_FA6_Cleaned_with_s.txt')\n","\n","xls = pd.ExcelFile(FA06_XLS, engine='xlrd')\n","\n","# --- helpers: reproduce Demultiplex_384W mapping and environment assignment ---\n","rows384 = list('ABCDEFGHIJKLMNOP')  # 16 rows\n","rows96  = list('ABCDEFGH')         # 8 rows\n","\n","def well96_from_384(w384: str) -> str:\n","    \"\"\"Map a 384-well coordinate (A1..P24) to a 96-well coordinate (A01..H12).\n","    This matches what happens after `Demultiplex_384W(..., flat=TRUE)`.\n","    \"\"\"\n","    row = w384[0]\n","    col = int(w384[1:])\n","    r_i = rows384.index(row) + 1\n","    r96 = rows96[(r_i - 1) // 2]\n","    c96 = (col + 1) // 2\n","    return f\"{r96}{c96:02d}\"\n","\n","def comp_env_from_384(w384: str) -> str:\n","    \"\"\"Environment assignment used in ParsingData.R:\n","    pl1=YPD, pl2=SC_37C, pl3=SCpH73, pl4=SC_NaCl\n","    which corresponds to (row parity, col parity) in the 384 coordinate.\n","    \"\"\"\n","    row = w384[0]\n","    col = int(w384[1:])\n","    r_i = rows384.index(row) + 1\n","    if (r_i % 2 == 1) and (col % 2 == 1):\n","        return 'YPD'\n","    if (r_i % 2 == 1) and (col % 2 == 0):\n","        return 'SC_37C'\n","    if (r_i % 2 == 0) and (col % 2 == 1):\n","        return 'SCpH73'\n","    return 'SC_NaCl'\n","\n","def norm384(w384: str) -> str:\n","    \"\"\"Match the formatting in the R output: A01, A02, ...\"\"\"\n","    return f\"{w384[0]}{int(w384[1:]):02d}\""]},{"cell_type":"code","execution_count":null,"id":"6c1587b5","metadata":{"id":"6c1587b5"},"outputs":[],"source":["# --- parse one FlowJo export sheet (384 wells * 2 rows: total + /Reference) ---\n","def parse_flowjo_sheet(sheet_name: str) -> pd.DataFrame:\n","    # Uses columns (1,2,4) => Name + #Cells (we don't need the extra plate column)\n","    df = pd.read_excel(xls, sheet_name=sheet_name, usecols=[1, 3])\n","    df.columns = ['Name', 'Cell_counts']\n","\n","    is_ref = df['Name'].astype(str).str.contains('/Reference', na=False)\n","\n","    # Extract 384-well ID from the Name field (token after Specimen_###_)\n","    # e.g. \"Specimen_001_A21_A21.fcs\" -> \"A21\"\n","    def extract_384(name: str) -> str:\n","        m = re.search(r\"Specimen_\\d+_([A-P]\\d{1,2})_\", str(name))\n","        return m.group(1) if m else np.nan\n","\n","    df['Well_id_384'] = df['Name'].apply(extract_384)\n","    df['Well_id_96']  = df['Well_id_384'].apply(lambda w: well96_from_384(w) if isinstance(w, str) else np.nan)\n","\n","    df_all = df.loc[~is_ref, ['Well_id_384', 'Well_id_96', 'Cell_counts']].rename(columns={'Cell_counts': 'nAll'})\n","    df_ref = df.loc[ is_ref, ['Well_id_384', 'Cell_counts']].rename(columns={'Cell_counts': 'nRef'})\n","\n","    out = df_all.merge(df_ref, on='Well_id_384', how='left')\n","\n","    out['Plate'] = sheet_name[:3]  # \"P1_\", ..., \"P9_\", \"P10\"\n","    out['Comp_env'] = out['Well_id_384'].apply(comp_env_from_384)\n","    out['time_point'] = 1 if sheet_name.endswith('_t1') else 2\n","\n","    # Downstream uses Well_id_384 formatted like \"A01\"\n","    out['Well_id_384'] = out['Well_id_384'].apply(norm384)\n","\n","    return out[['Plate', 'Well_id_96', 'Well_id_384', 'Comp_env', 'time_point', 'nRef', 'nAll']]\n","\n","flow_sheets = [s for s in xls.sheet_names if s != 'Plate_Layout_FA6']\n","parsed = pd.concat([parse_flowjo_sheet(s) for s in flow_sheets], ignore_index=True)\n","#parsed.shape"]},{"cell_type":"code","execution_count":null,"id":"84ff0551","metadata":{"id":"84ff0551"},"outputs":[],"source":["# --- reshape to wide (t1/t2 on one row) ---\n","t1 = parsed[parsed.time_point == 1].drop(columns=['time_point']).rename(columns={'nRef': 'nRef_t1', 'nAll': 'nAll_t1'})\n","t2 = parsed[parsed.time_point == 2].drop(columns=['time_point']).rename(columns={'nRef': 'nRef_t2', 'nAll': 'nAll_t2'})\n","\n","wide = t1.merge(t2, on=['Plate', 'Well_id_96', 'Well_id_384', 'Comp_env'], how='inner')\n","\n","# --- attach layout info (Type, Parent_id, Evolution) ---\n","layout = pd.read_excel(xls, sheet_name='Plate_Layout_FA6')\n","layout = layout[['Well_id_96', 'Type', 'Parent_id', 'Evolution']]\n","wide = wide.merge(layout, on='Well_id_96', how='left')\n","\n","# FlowJo missing marker used in the R scripts\n","wide.loc[wide['nRef_t1'] == 9999999, 'nRef_t1'] = np.nan\n","wide.loc[wide['nAll_t1'] == 9999999, 'nAll_t1'] = np.nan\n","\n","# Fitness vs reference\n","dt = 20 - 10\n","num = ((wide['nAll_t2'] - wide['nRef_t2']) / wide['nRef_t2'])\n","den = ((wide['nAll_t1'] - wide['nRef_t1']) / wide['nRef_t1'])\n","wide['s_vs_Ref'] = np.log(num / den) / dt\n","#wide.shape"]},{"cell_type":"code","execution_count":null,"id":"4616be9c","metadata":{"id":"4616be9c"},"outputs":[],"source":["# --- SanityCheckCleaning.R (flags + cleaning) ---\n","min_events = 2000\n","\n","min_ref_start = 0.1\n","max_ref_start = 0.8\n","\n","min_ref_end = 0.05\n","max_ref_end = 0.95\n","\n","G = wide.copy()\n","\n","# flags\n","G['low_events']  = ((G['nAll_t1'] < min_events) | (G['nAll_t2'] < min_events)).astype(int)\n","G['high_ref_t1'] = 0\n","G['low_ref_t1']  = (G['nRef_t1'] / G['nAll_t1'] < min_ref_start).astype(int)\n","G['high_ref_t2'] = (G['nRef_t2'] / G['nAll_t2'] > max_ref_end).astype(int)\n","G['low_ref_t2']  = (G['nRef_t2'] / G['nAll_t2'] < min_ref_end).astype(int)\n","\n","# High ref at t1:\n","# Block 1: remove everything except Offspring/Adapted_Parent, and flag those.\n","ref_frac_t1 = G['nRef_t1'] / G['nAll_t1']\n","remove_mask1 = (ref_frac_t1 > max_ref_start) & (~G['Type'].isin(['Offspring', 'Adapted_Parent']))\n","G = G.loc[~remove_mask1].copy()\n","ref_frac_t1 = G['nRef_t1'] / G['nAll_t1']\n","G.loc[(ref_frac_t1 > max_ref_start) & (G['Type'].isin(['Offspring', 'Adapted_Parent'])), 'high_ref_t1'] = 1\n","\n","# Block 2 (\"Alternative solution\"): recompute ToRemove/ToFlag, but since Block 1 already removed ancestors,\n","# this effectively just re-flags the remaining rows. We reproduce that behavior.\n","ref_frac_t1 = G['nRef_t1'] / G['nAll_t1']\n","remove_mask2 = (ref_frac_t1 > max_ref_start) & (~G['Type'].isin(['Offspring', 'Adapted_Parent', 'Anc_alpha', 'Anc_a']))\n","G = G.loc[~remove_mask2].copy()\n","ref_frac_t1 = G['nRef_t1'] / G['nAll_t1']\n","G['high_ref_t1'] = ((ref_frac_t1 > max_ref_start) & (G['Type'].isin(['Offspring', 'Adapted_Parent', 'Anc_alpha', 'Anc_a']))).astype(int)\n","\n","# Recompute these flags after any row removals\n","G['low_ref_t1']  = (G['nRef_t1'] / G['nAll_t1'] < min_ref_start).astype(int)\n","G['high_ref_t2'] = (G['nRef_t2'] / G['nAll_t2'] > max_ref_end).astype(int)\n","G['low_ref_t2']  = (G['nRef_t2'] / G['nAll_t2'] < min_ref_end).astype(int)\n","\n","# Evaporation exclusions\n","def r_paste_row0(letter, nums):\n","    return [f\"{letter}0{n}\" for n in nums]\n","\n","exclude_evap = {\n","    1: [*(f\"{l}01\" for l in \"ABCDEFGH\"), \"A02\", *r_paste_row0(\"H\", range(1, 13))],\n","    2: [\"A12\", \"B12\", \"C12\"],\n","    3: [\"A1\", \"A2\", \"A11\", \"H12\", \"A12\", \"B12\", \"C12\"],\n","    4: [\"H12\", \"A12\", \"A1\"],\n","    5: [*r_paste_row0(\"E\", range(1, 13)), *r_paste_row0(\"F\", range(1, 13)),\n","        *r_paste_row0(\"G\", range(1, 13)), *r_paste_row0(\"H\", range(1, 13))],\n","    6: [*r_paste_row0(\"A\", range(1, 13)), \"B01\", \"B12\", \"C01\", \"C12\"],\n","    7: [*(f\"{l}01\" for l in \"ABCDEFGH\"), *r_paste_row0(\"A\", [2,3,4,10,11,12])],\n","    8: [\"A01\", \"A02\", \"A03\", \"A12\", \"B01\"],\n","    9: [\"F1\", \"G1\", *r_paste_row0(\"H\", range(1, 13))],\n","    10: [\"A12\"],\n","}\n","\n","plates = ['P1_', 'P2_', 'P3_', 'P4_', 'P5_', 'P6_', 'P7_', 'P8_', 'P9_', 'P10']\n","\n","for i, plate in enumerate(plates, start=1):\n","    wells = set(exclude_evap[i])\n","    mask = (G['Plate'] == plate) & (G['Comp_env'] == 'SC_37C') & (G['Well_id_96'].isin(wells))\n","    G = G.loc[~mask].copy()\n","\n","# Remove too few events\n","G = G.loc[G['low_events'] != 1].copy()\n","\n","# Remove wells where ref started low AND ended low\n","G = G.loc[~((G['low_ref_t2'] == 1) & (G['low_ref_t1'] == 1))].copy()\n","#G.shape"]},{"cell_type":"code","execution_count":null,"id":"30f49d47","metadata":{"id":"30f49d47"},"outputs":[],"source":["# --- ancestor handling + compute s ---\n","\n","# Remove remaining outlier among Anc_alpha\n","out_idx = G.index[(G['Type'] == 'Anc_alpha') & (G['s_vs_Ref'] < -0.14)].tolist()\n","G = G.drop(index=out_idx)\n","\n","# Replace P2_ Anc_alpha SCpH73 by mean across all other plates\n","mean_other = G.loc[(G['Plate'] != 'P2_') & (G['Type'] == 'Anc_alpha') & (G['Comp_env'] == 'SCpH73'), 's_vs_Ref'].mean()\n","G.loc[(G['Plate'] == 'P2_') & (G['Type'] == 'Anc_alpha') & (G['Comp_env'] == 'SCpH73'), 's_vs_Ref'] = mean_other\n","\n","# Ancestor fitness per plate+env (using only Anc_alpha), then compute s\n","anc = (G.loc[G['Type'] == 'Anc_alpha']\n","         .groupby(['Comp_env', 'Plate'], as_index=False)['s_vs_Ref']\n","         .mean()\n","         .rename(columns={'s_vs_Ref': 'Anc_Fit'}))\n","\n","G = G.merge(anc, on=['Plate', 'Comp_env'], how='left')\n","G['s'] = G['s_vs_Ref'] - G['Anc_Fit']\n","\n","G['unique_cond'] = G['Plate'] + '_' + G['Comp_env']\n","\n","# Final column order\n","out = G[['Parent_id','Well_id_96','Well_id_384','Type','Plate','Evolution','Comp_env',\n","         'nRef_t1','nAll_t1','nRef_t2','nAll_t2','s_vs_Ref',\n","         'low_events','high_ref_t1','low_ref_t1','high_ref_t2','low_ref_t2',\n","         'unique_cond','Anc_Fit','s']].copy()\n","\n","#out.shape"]},{"cell_type":"code","execution_count":null,"id":"49c40cc6","metadata":{"id":"49c40cc6"},"outputs":[],"source":["\n","# --- write output ---\n","\n","out_to_write = out.copy()\n","\n","# --- match row order exactly ---\n","\n","# Plate order: P1_..P9_, then P10 (no underscore)\n","plate_order = {f\"P{i}_\": i for i in range(1, 10)}\n","plate_order[\"P10\"] = 10\n","\n","# Comp_env order\n","env_order = {\n","    \"YPD\": 0,\n","    \"SC_37C\": 1,\n","    \"SCpH73\": 2,\n","    \"SC_NaCl\": 3,\n","}\n","\n","out_to_write[\"_plate_num\"] = out_to_write[\"Plate\"].map(plate_order)\n","out_to_write[\"_env_num\"] = out_to_write[\"Comp_env\"].map(env_order)\n","\n","out_to_write[\"_well_row\"] = out_to_write[\"Well_id_384\"].astype(str).str.extract(r\"^([A-H])\", expand=False)\n","out_to_write[\"_well_col\"] = pd.to_numeric(\n","    out_to_write[\"Well_id_384\"].astype(str).str.extract(r\"(\\d+)$\", expand=False),\n","    errors=\"coerce\"\n",")\n","\n","out_to_write = (\n","    out_to_write\n","    .sort_values(\n","        [\"_plate_num\", \"_env_num\", \"_well_row\", \"_well_col\"],\n","        kind=\"mergesort\"\n","    )\n","    .drop(columns=[\"_plate_num\", \"_env_num\", \"_well_row\", \"_well_col\"], errors=\"ignore\")\n",")\n","\n","# Reset index so row numbers become \"1\",\"2\",\"3\",...\n","out_to_write = out_to_write.reset_index(drop=True)\n","\n","# Define which columns should be treated as numeric (so they print unquoted)\n","numeric_cols = [\n","    \"nRef_t1\",\"nAll_t1\",\"nRef_t2\",\"nAll_t2\",\n","    \"s_vs_Ref\",\"low_events\",\n","    \"high_ref_t1\",\"low_ref_t1\",\"high_ref_t2\",\"low_ref_t2\",\n","    \"Anc_Fit\",\"s\",\n","]\n","for c in numeric_cols:\n","    if c in out_to_write.columns:\n","        out_to_write[c] = pd.to_numeric(out_to_write[c], errors=\"coerce\")\n","\n","# - header is ONLY the real column names (quoted)\n","# - each data row begins with quoted row number \"1\",\"2\",...\n","# - strings quoted; numbers unquoted; NA unquoted\n","# - CRLF line endings\n","def fmt_cell(val):\n","    if pd.isna(val):\n","        return \"NA\"\n","    # numbers (ints/floats) -> unquoted\n","    if isinstance(val, (int, np.integer)):\n","        return str(int(val))\n","    if isinstance(val, (float, np.floating)):\n","        # match R-like precision pretty well\n","        return format(float(val), \".17g\")\n","    # everything else -> quoted string\n","    return f\"\\\"{str(val)}\\\"\"\n","\n","with open(OUT_TXT, \"w\", newline=\"\") as f:\n","    # header (no leading blank field)\n","    header = \"\\t\".join([f\"\\\"{c}\\\"\" for c in out_to_write.columns])\n","    f.write(header + \"\\r\\n\")\n","\n","    # rows with leading quoted row number\n","    for i, row in out_to_write.iterrows():\n","        rownum = f\"\\\"{i+1}\\\"\"\n","        fields = [fmt_cell(row[c]) for c in out_to_write.columns]\n","        f.write(rownum + \"\\t\" + \"\\t\".join(fields) + \"\\r\\n\")\n","\n","#print(\"Wrote:\", OUT_TXT.resolve())"]},{"cell_type":"markdown","source":["# FA06\n","\n","**Input**: `GGE_FA6_Cleaned_with_s.txt`, `FA06_parent_kk_strain_map.txt`\n","\n","**Output**: `fa06_F1_final.csv`, `fa06_Parents_final.csv`\n"],"metadata":{"id":"eSzSN1W17PVS"},"id":"eSzSN1W17PVS"},{"cell_type":"code","source":["\n","# ---- inputs ----\n","IN_TXT  = \"GGE_FA6_Cleaned_with_s.txt\"\n","KK_MAP  = \"FA06_parent_kk_strain_map.txt\"\n","\n","OUT_F1  = \"fa06_F1_final.csv\"\n","OUT_PAR = \"fa06_Parents_final.csv\"\n","\n","\n","def read_gge_cleaned(path: str) -> pd.DataFrame:\n","    \"\"\"\n","    Reads the R-style TSV (quoted headers/strings, NA tokens, row-number col).\n","    Drops the leading row-number column if present.\n","    \"\"\"\n","    df = pd.read_csv(\n","        path,\n","        sep=\"\\t\",\n","        quotechar='\"',\n","        na_values=[\"NA\"],\n","        keep_default_na=True,\n","        dtype=str,  # read as str first; we'll cast selected columns later\n","    )\n","    # Drop possible row-number column (blank header or Unnamed)\n","    if df.columns[0] == \"\" or str(df.columns[0]).startswith(\"Unnamed\"):\n","        df = df.iloc[:, 1:]\n","    return df\n","\n","\n","def fit_est_from_freq(f0: pd.Series, f1: pd.Series, t: float = 10.0) -> pd.Series:\n","    \"\"\"\n","    Mirrors fit_est in the R header used here:\n","      s_hat = (logit(f1) - logit(f0)) / t\n","    \"\"\"\n","    eps = 1e-12\n","    f0c = f0.clip(eps, 1 - eps)\n","    f1c = f1.clip(eps, 1 - eps)\n","    return (np.log(f1c / (1 - f1c)) - np.log(f0c / (1 - f0c))) / t\n","\n","\n","# ---- 1) Load data ----\n","FA06 = read_gge_cleaned(IN_TXT)\n","\n","# Cast numeric columns needed for s_hat / QC / downstream calculations\n","num_cols = [\"nRef_t1\", \"nAll_t1\", \"nRef_t2\", \"nAll_t2\",\n","            \"high_ref_t1\", \"low_ref_t1\", \"high_ref_t2\", \"low_ref_t2\",\n","            \"low_events\"]\n","for c in num_cols:\n","    if c in FA06.columns:\n","        FA06[c] = pd.to_numeric(FA06[c], errors=\"coerce\")\n","\n","# ---- 2) Merge parent_id -> kk_strain_id map and derive kk fields ----\n","kkmap = pd.read_csv(KK_MAP, sep=\"\\t\", dtype=str)\n","FA06 = FA06.merge(kkmap, on=\"Parent_id\", how=\"left\", sort=False)\n","\n","# kk_well_id: 3rd underscore-delimited token of kk_strain_id\n","FA06[\"kk_well_id\"] = FA06[\"kk_strain_id\"].astype(str).str.split(\"_\").str[2]\n","\n","# kk_pop_id: remove leading [A-Z][0-9]+_ ; then remove trailing _[0-9] (well replicate)\n","FA06[\"kk_pop_id\"] = (\n","    FA06[\"kk_strain_id\"]\n","    .astype(str)\n","    .str.replace(r\"^[A-Z][0-9]+_\", \"\", regex=True)\n","    .str.replace(r\"_[0-9]$\", \"\", regex=True)\n",")\n","\n","# regime from kk_pop_id\n","FA06[\"regime\"] = np.nan\n","FA06.loc[FA06[\"kk_pop_id\"].str.contains(\"a3\", na=False), \"regime\"] = \"sexual\"\n","FA06.loc[FA06[\"kk_pop_id\"].str.contains(\"a1.1\", na=False), \"regime\"] = \"asexual\"\n","\n","# ---- 3) env / plate naming ----\n","FA06[\"env\"] = \"YPD\"\n","FA06.loc[FA06[\"Comp_env\"] == \"SC_37C\", \"env\"]  = \"SC37C\"\n","FA06.loc[FA06[\"Comp_env\"] == \"SC_NaCl\", \"env\"] = \"SC_0.2M_NaCl\"\n","FA06.loc[FA06[\"Comp_env\"] == \"SCpH73\", \"env\"]  = \"SC_pH7.3\"\n","\n","# plate = env + '_' + Plate (strip trailing underscore from Plate)\n","FA06[\"plate\"] = FA06[\"env\"].astype(str) + \"_\" + FA06[\"Plate\"].astype(str).str.replace(r\"_$\", \"\", regex=True)\n","\n","# ---- 4) s_hat from counts ----\n","f0 = (FA06[\"nAll_t1\"] - FA06[\"nRef_t1\"]) / FA06[\"nAll_t1\"]\n","f1 = (FA06[\"nAll_t2\"] - FA06[\"nRef_t2\"]) / FA06[\"nAll_t2\"]\n","FA06[\"s_hat\"] = fit_est_from_freq(f0=f0, f1=f1, t=10.0)\n","\n","# flags\n","FA06[\"F1\"] = FA06[\"Type\"].astype(str).str.contains(\"Offspring\", na=False).astype(int)\n","FA06[\"parent\"] = FA06[\"Type\"].astype(str).str.contains(\"Parent\", na=False).astype(int)\n","\n","# ---- 5) Plate effect correction ----\n","# R does: FA06p <- filter(FA06, parent==1) then remove col07 parents, then glmmTMB with dispformula=~env\n","# and uses ranef(FA06_pm1)[[1]]$plate (random intercepts) as plate_means.\n","\n","# Ensure these exist and are correct BEFORE this block:\n","#   FA06 has columns: s_hat, regime, env, kk_strain_id, plate, parent, Well_id_96\n","\n","FA06p = FA06[FA06[\"parent\"] == 1].copy()\n","FA06p = FA06p[~FA06p[\"Well_id_96\"].astype(str).str.contains(\"07\", na=False)].copy()\n","\n","# Make sure R sees factors similarly\n","FA06p[\"regime\"] = FA06p[\"regime\"].astype(\"string\")\n","FA06p[\"env\"] = FA06p[\"env\"].astype(\"string\")\n","FA06p[\"kk_strain_id\"] = FA06p[\"kk_strain_id\"].astype(\"string\")\n","FA06p[\"plate\"] = FA06p[\"plate\"].astype(\"string\")\n","\n","# Install/load rpy2 + glmmTMB (Colab)\n","import sys, subprocess\n","subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rpy2\"])\n","\n","import rpy2.robjects as ro\n","from rpy2.robjects import pandas2ri\n","pandas2ri.activate()\n","\n","# Ensure glmmTMB is installed in the R runtime\n","ro.r('if(!requireNamespace(\"glmmTMB\", quietly=TRUE)) install.packages(\"glmmTMB\", repos=\"https://cloud.r-project.org\")')\n","ro.r('library(glmmTMB)')\n","\n","# Send FA06p to R and fit the exact model\n","ro.globalenv[\"FA06p\"] = pandas2ri.py2rpy(FA06p)\n","\n","ro.r(r'''\n","FA06p <- droplevels(FA06p)\n","\n","# exact model used in FA06_parsing.R:\n","m <- glmmTMB(\n","  s_hat ~ regime * env + (1|kk_strain_id) + (1|plate),\n","  dispformula = ~ env,\n","  data = FA06p,\n","  family = gaussian\n",")\n","\n","re_plate <- ranef(m)[[1]]$plate\n","plate_effect_FA06 <- data.frame(\n","  plate = row.names(re_plate),\n","  plate_means = re_plate[,1],\n","  row.names = NULL\n",")\n","''')\n","\n","plate_effect_df = pandas2ri.rpy2py(ro.globalenv[\"plate_effect_FA06\"])\n","\n","# Merge plate effects back EXACTLY like R: merge(..., by='plate', sort=F)\n","# In pandas: preserve FA06 row order by doing left merge on FA06.\n","FA06c = FA06.merge(plate_effect_df, on=\"plate\", how=\"left\", sort=False)\n","FA06c[\"fitness_gain\"] = FA06c[\"s_hat\"] - FA06c[\"plate_means\"]\n","\n","\n","\n","# ---- 6) Parents: QC filter + remove col07 + average ----\n","qc_ok = (\n","    (FA06c[\"high_ref_t1\"].fillna(0) == 0) &\n","    (FA06c[\"low_ref_t1\"].fillna(0) == 0) &\n","    (FA06c[\"high_ref_t2\"].fillna(0) == 0) &\n","    (FA06c[\"low_ref_t2\"].fillna(0) == 0)\n",")\n","FA06p3 = FA06c[(FA06c[\"parent\"] == 1) & qc_ok].copy()\n","\n","# remove col 07 parents (Well_id_96 contains '07')\n","FA06p3 = FA06p3[~FA06p3[\"Well_id_96\"].astype(str).str.contains(\"07\", na=False)].copy()\n","\n","Ps = (\n","    FA06p3.groupby([\"regime\", \"kk_strain_id\", \"env\"], dropna=False)\n","    .agg(mu_s=(\"fitness_gain\", \"mean\"),\n","         sd_s=(\"fitness_gain\", \"std\"),\n","         n_s=(\"fitness_gain\", \"size\"))\n","    .reset_index()\n",")\n","\n","# ---- 7) F1s: subset ----\n","F1s = FA06c[(FA06c[\"F1\"] == 1) & (FA06c[\"parent\"] == 0)].copy()\n","\n","# ---- 8) Environment means (computed from F1 + parent mu_s) ----\n","F1_subset = F1s[[\"regime\", \"kk_strain_id\", \"env\", \"fitness_gain\"]].copy()\n","F1_subset = F1_subset.rename(columns={\"fitness_gain\": \"mu_s\"})\n","\n","Ps_for_means = Ps.drop(columns=[\"sd_s\", \"n_s\"]).copy()\n","FA06_m = pd.concat([F1_subset, Ps_for_means], ignore_index=True)\n","\n","env_means = (\n","    FA06_m.groupby(\"env\", dropna=False)[\"mu_s\"]\n","    .mean()\n","    .reset_index()\n","    .rename(columns={\"mu_s\": \"env_means\"})\n",")\n","\n","# Merge back\n","F1s_2 = F1s.merge(env_means, on=\"env\", how=\"left\")\n","Ps_2  = Ps.merge(env_means, on=\"env\", how=\"left\")\n","\n","# Centered fitness\n","F1s_2[\"fitness_gain_adj\"] = F1s_2[\"fitness_gain\"] - F1s_2[\"env_means\"]\n","Ps_2[\"fitness_gain_adj\"]  = Ps_2[\"mu_s\"] - Ps_2[\"env_means\"]\n","\n","# F1 unique id\n","F1s_2[\"f1_unique_id\"] = (\n","    F1s_2[\"kk_strain_id\"].astype(str) + \"_\" +\n","    F1s_2[\"Plate\"].astype(str) + F1s_2[\"Well_id_96\"].astype(str)\n",")\n","\n","# ---- 9) Force exact column order (match fa06_*_final.csv) ----\n","\n","f1_cols = [\n","    'env','plate','Parent_id','Well_id_96','Well_id_384','Type','Plate','Evolution','Comp_env',\n","    'nRef_t1','nAll_t1','nRef_t2','nAll_t2','s_vs_Ref','low_events',\n","    'high_ref_t1','low_ref_t1','high_ref_t2','low_ref_t2',\n","    'unique_cond','Anc_Fit','s',\n","    'kk_strain_id','kk_well_id','kk_pop_id','regime',\n","    's_hat','F1','parent',\n","    'plate_means','fitness_gain','env_means','fitness_gain_adj','f1_unique_id'\n","]\n","\n","parent_cols = [\n","    'env','regime','kk_strain_id',\n","    'mu_s','sd_s','n_s',\n","    'env_means','fitness_gain_adj'\n","]\n","\n","# Keep only columns that exist (safety)\n","F1s_2 = F1s_2[[c for c in f1_cols if c in F1s_2.columns]]\n","Ps_2  = Ps_2[[c for c in parent_cols if c in Ps_2.columns]]\n","\n","# ---- write outputs ----\n","F1s_2.to_csv(OUT_F1, index=False)\n","Ps_2.to_csv(OUT_PAR, index=False)\n","\n","print(\"Wrote:\", OUT_F1, \"rows:\", len(F1s_2), \"cols:\", F1s_2.shape[1])\n","print(\"Wrote:\", OUT_PAR, \"rows:\", len(Ps_2), \"cols:\", Ps_2.shape[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dCaDqgM27ln1","executionInfo":{"status":"ok","timestamp":1770485114210,"user_tz":300,"elapsed":597095,"user":{"displayName":"Shreyas Pai","userId":"15597218115471730073"}},"outputId":"df01cfcc-65fc-48a3-9d2d-c279106b445e"},"id":"dCaDqgM27ln1","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-857646435.py:67: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'sexual' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  FA06.loc[FA06[\"kk_pop_id\"].str.contains(\"a3\", na=False), \"regime\"] = \"sexual\"\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: also installing the dependencies ‘xts’, ‘TTR’, ‘quadprog’, ‘quantmod’, ‘colorspace’, ‘fracdiff’, ‘lmtest’, ‘timeDate’, ‘tseries’, ‘urca’, ‘RcppArmadillo’, ‘rbibutils’, ‘cowplot’, ‘Deriv’, ‘forecast’, ‘microbenchmark’, ‘minqa’, ‘nloptr’, ‘Rdpack’, ‘doBy’, ‘zoo’, ‘TMB’, ‘lme4’, ‘numDeriv’, ‘reformulas’, ‘pbkrtest’, ‘sandwich’, ‘RcppEigen’\n","\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/xts_0.14.1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/TTR_0.24.4.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/quadprog_1.5-8.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/quantmod_0.4.28.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/colorspace_2.1-2.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/fracdiff_1.5-3.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lmtest_0.9-40.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/timeDate_4052.112.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/tseries_0.10-59.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/urca_1.3-4.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/RcppArmadillo_15.2.3-1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/rbibutils_2.4.1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/cowplot_1.2.0.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/Deriv_4.2.0.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/forecast_9.0.0.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/microbenchmark_1.5.0.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/minqa_1.2.8.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/nloptr_2.2.1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/Rdpack_2.6.5.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/doBy_4.7.1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/zoo_1.8-15.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/TMB_1.9.19.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lme4_1.1-38.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/numDeriv_2016.8-1.1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/reformulas_0.4.4.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/pbkrtest_0.5.5.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/sandwich_3.1-1.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/RcppEigen_0.3.4.0.2.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/glmmTMB_1.1.14.tar.gz'\n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n","\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: The downloaded source packages are in\n","\t‘/tmp/RtmpL7kHNn/downloaded_packages’\n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n","WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: \n","\n"]},{"output_type":"stream","name":"stdout","text":["Wrote: fa06_F1_final.csv rows: 2442 cols: 34\n","Wrote: fa06_Parents_final.csv rows: 32 cols: 8\n"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["88680bfa"]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}